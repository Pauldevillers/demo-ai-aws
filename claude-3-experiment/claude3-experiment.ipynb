{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<h1 align=\"center\">ðŸš€ Advancing AI frontiers with Claude 3</h1>\n",
    "\n",
    "----\n",
    "\n",
    "## ðŸ› ï¸ TLDR : Build 5 vision and text use cases with Claude 3 Sonnet on Amazon Bedrock:\n",
    "\n",
    "\n",
    "- **1. Q&A answer from AWS Architecture image** :\n",
    "Learn how to integrate Claude 3 Sonnet into your AWS architecture to enhance AI capabilities. ðŸ—ï¸\n",
    "\n",
    "- **2 Automate Terraform script from AWS architecture image**:\n",
    "Learn how to build a Terraform deployment with AWS architecture images using Claude 3 Sonnet. ðŸ› ï¸\n",
    "\n",
    "- **3. Side by Side Image Comparison**:\n",
    "Discover the power of image comparison using Claude 3 Sonnet on Amazon Bedrock. ðŸ–¼ï¸\n",
    "\n",
    "- **4. Image Transcription**:\n",
    "Explore the capabilities of image transcription with Claude 3 Sonnet on Amazon Bedrock. ðŸ“\n",
    "\n",
    "- **5. Streaming text reponse**:\n",
    "Understand how to use Claude 3 Sonnet for streaming text responses. ðŸ“œ\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction to Claude 3\n",
    "\n",
    "Anthropic unveils the Claude 3 model family, featuring Haiku, Sonnet, and Opus. ðŸŒ\n",
    "\n",
    "These models redefine AI capabilities, catering to diverse needs. Claude 3 Sonnet is available for immediate use on Amazon Bedrock, with Claude 3 Opus and Claude 3 Haiku coming soon. ðŸ’»\n",
    "\n",
    "Claude 3 Sonnet strikes the ideal balance between intelligence and speedâ€”particularly for enterprise workloads. It delivers robust performance at a lower cost compared to its peers and is engineered for high endurance in large-scale AI deployments. Moreover, it introduces image-to-text vision capabilities! ðŸ“¸\n",
    "\n",
    "**Potential uses**:\n",
    "- Data processing: RAG or search & retrieval over vast amounts of knowledge ðŸ“š\n",
    "- Sales: product recommendations, forecasting, targeted marketing ðŸ“ˆ\n",
    "- Time-saving tasks: code generation, quality control, parse text from images â°\n",
    "\n",
    "**Differentiator**: More affordable than other models with similar intelligence; better for scale. ðŸ’°\n",
    "\n",
    "**Key features**:\n",
    "\n",
    "- ðŸ“Š **Context Window:** 200,000 tokens\n",
    "\n",
    "- âš¡ **Speed:** 2x faster than Claude 2 and Claude 2.1\n",
    "\n",
    "- ðŸ‘ï¸ **Vision Capabilities:** Handles a wide range of visual formats, including photos, charts, graphs, and technical diagrams.\n",
    "\n",
    "- ðŸš« **Refusals:** Claude 3 models (including Sonnet) significantly reduce unnecessary refusals compared to previous generations.\n",
    "\n",
    "- ðŸ›¡ï¸ **Safety Level:** Maintains AI Safety Level 2 (ASL-2) per the Responsible Scaling Policy.\n",
    "\n",
    "- ðŸš€ **Model Speed Comparison:** Sonnet is 2x faster than Claude 2 and Claude 2.1, excelling at tasks demanding rapid responses.\n",
    "\n",
    "\n",
    "### Pre-requisites:\n",
    "\n",
    "- **AWS Account**: To use Amazon Bedrock and deploy the use cases.\n",
    "- **Amazon Bedrock IAM permissions** : Amazon Bedrock IAM permissions to run this notebook. More details [here](https://docs.aws.amazon.com/bedrock/latest/userguide/iam-permissions.html)\n",
    "\n",
    "Enable AWS IAM permissions for Bedrock\n",
    "The AWS identity you assume from your notebook environment (which is the Studio/notebook Execution Role from SageMaker, or could be a role or IAM User for self-managed notebooks), must have sufficient AWS IAM permissions to call the Amazon Bedrock service.\n",
    "\n",
    "To grant Bedrock access to your identity, you can:\n",
    "\n",
    "Open the AWS IAM Console\n",
    "Find your Role (if using SageMaker or otherwise assuming an IAM Role), or else User\n",
    "Select Add Permissions > Create Inline Policy to attach new inline permissions, open the JSON editor and paste in the below example policy:\n",
    "\n",
    "\n",
    "```json \n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"BedrockFullAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\"bedrock:*\"],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case : 1 AWS Architecture Explanation\n",
    "\n",
    "In this use case, we will explore how to integrate Claude 3 Sonnet to help you answer questions about your AWS architecture. This can be particularly useful for large-scale deployments, where it can be challenging to keep track of all the moving parts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install latest version of boto3\n",
    "!pip install boto3==1.33.2 termcolor matplotlib ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, re,json\n",
    "import boto3\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def display_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        display(Image(data=image_file.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\"images/architecture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Claude 3 family of models comes with new vision capabilities that allow Claude to understand and analyze images, opening up exciting possibilities for multimodal interaction. With Claude, you can now provide both text and image inputs to enrich your conversations and enable powerful new use cases.\n",
    "\n",
    "\n",
    "To utilize images when making an API request, you can provide images to Claude as a ``base64-encoded`` image in image content blocks. Here is simple example in Python showing how to include a base64-encoded image in a Messages API request:\n",
    "\n",
    "```python\n",
    "messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image1_media_type,\n",
    "                        \"data\": image1_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "```\n",
    "\n",
    "Supported image formats are ``JPEG, PNG, GIF, and WebP``. See Messages [API examples](https://docs.anthropic.com/claude/reference/messages_post) for more example code and parameter details.\n",
    "\n",
    "Below we defined two funtions to help you get started with image processing using Claude 3 Sonnet on Amazon Bedrock:\n",
    "\n",
    "- ``post_process_answer()`` : This function extracts answer from the Bedrock API response. A best pratice frome [Claude prompt engineering](https://docs.anthropic.com/claude/docs/prefill-claudes-response) is to output the answer inside <answer></answer> XML tags. This function will extract the answer from the API response.\n",
    "- ``generate_vision_answer()`` : This function will generate the API request to send the image to the Claude 3 Sonnet model to Amazon Bedrock. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_answer(response:str)->str:\n",
    "    \"\"\"\n",
    "    Extracts the answer from the given response string.\n",
    "\n",
    "    Args:\n",
    "        response (str): The response string containing the answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted answer.\n",
    "    \"\"\"\n",
    "    answer = re.findall(r'<answer>(.*?)</answer>', response, re.DOTALL)\n",
    "    return answer[0]\n",
    "\n",
    "def generate_vision_answer(bedrock_rt:boto3.client,messages:list, model_id:str, claude_config:dict,system_prompt:str):\n",
    "    \"\"\"\n",
    "    Generates a vision answer using the specified model and configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    - bedrock_rt (boto3.client): The Bedrock runtime client.\n",
    "    - messages (list): A list of messages.\n",
    "    - model_id (str): The ID of the model to use.\n",
    "    - claude_config (dict): The configuration for Claude.\n",
    "    - system_prompt (str): The system prompt.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The formatted response.\n",
    "    \"\"\"\n",
    "    \n",
    "    body={'messages': [messages],**claude_config, \"system\": system_prompt}\n",
    "    \n",
    "    response = bedrock_rt.invoke_model(modelId=model_id, body=json.dumps(body))   \n",
    "    response = json.loads(response['body'].read().decode('utf-8'))\n",
    "    formated_response= post_process_answer(response['content'][0]['text'])\n",
    "    \n",
    "    return formated_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this use case, the goal is to ask a question about the AWS architecture and provide an image of the architecture. The image will be sent to the Claude 3 Sonnet model to generate a response. The response will be post-processed to extract the answer.\n",
    "\n",
    "To perform this task, we need a **system prompt**. This is a way of providing context and instructions to Claude, such as specifying a particular goal or role. See our guide to system prompts.\n",
    "\n",
    "An example system prompt for this use case could be:\n",
    "\n",
    "```\n",
    "You have perfect vision and pay great attention to detail which makes you an expert at answering architecture diagram question\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a bedrock runtime client in us-west-2\n",
    "bedrock_rt = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\", credential_provider='env')\n",
    "\n",
    "# Model id and claude config\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "claude_config = {\n",
    "    'max_tokens': 1000, \n",
    "    'temperature': 0, \n",
    "    'anthropic_version': '',  \n",
    "    'top_p': 1, \n",
    "    'stop_sequences': ['Human:']\n",
    "}\n",
    "\n",
    "# Create prompt and system prompt\n",
    "system_prompt= \"You have perfect vision and pay great attention to detail which makes you an expert at answering architecture diagram question. Answer question in <question></question> tags. Before answer, think step by step in <thinking> tags and analyze every part of the diagram.\"\n",
    "\n",
    "#Create a prompt with the question\n",
    "prompt = f\"<question>Explain why Amazon Gamelift is usefull on the diagram </question>. Answer must be a numbered list in a small paragraph inside <answer></answer> tag.\"\n",
    "\n",
    "# Create message with the prompt and the base64 encoded image\n",
    "messages={\"role\": \"user\", \"content\": [\n",
    "{\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\n",
    "        \"type\": \"base64\",\n",
    "        \"media_type\": \"image/jpeg\",\n",
    "        \"data\": image_to_base64(\"images/architecture.png\"),\n",
    "        }\n",
    "},\n",
    "{\"type\": \"text\", \"text\": prompt}\n",
    "]}\n",
    "\n",
    "# Generate answer\n",
    "answer=generate_vision_answer(bedrock_rt, messages, model_id, claude_config, system_prompt)    \n",
    "print(colored(answer, \"green\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 2: Create Terraform script from AWS architecture images using Claude 3 Sonnet on Amazon Bedrock\n",
    "\n",
    "In this use case, we will explore how to use Claude 3 Sonnet to generate a Terraform script from an AWS architecture image. This can be particularly useful for automating the deployment of AWS infrastructure. It will greatly reduce the time and effort required to create Terraform scripts from AWS architecture images.\n",
    "\n",
    "\n",
    "Here is a simple serveless architectiure diagram that we will use as an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\"images/serverless.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\n",
    "messages = {    \n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": \"image/jpeg\",\n",
    "                \"data\": image_to_base64(\"images/serverless.png\")\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Describe the architecture and code terraform script to deploy it, answer inside <answer></answer> tags.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate answer\n",
    "answer= generate_vision_answer(bedrock_rt, messages, model_id, claude_config, system_prompt=\"\")\n",
    "print(colored(answer, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case 3:  Side by side image comparaison using Claude 3 Sonnet on Amazon Bedrock\n",
    "\n",
    "In this use case, we will explore how to use Claude 3 Sonnet to compare two images side by side. This can be particularly useful for quality control and identifying differences between two images.\n",
    "\n",
    "#### Let's play a game!\n",
    "\n",
    "Can you spot the differences between the two images below?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "local_images = [\"images/image_1.png\", \"images/image_2.png\"]\n",
    "\n",
    "# figure size in inches optional\n",
    "rcParams['figure.figsize'] = 11 ,8\n",
    "\n",
    "# read images\n",
    "img_A = mpimg.imread(local_images[0])\n",
    "img_B = mpimg.imread(local_images[1])\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img_A)\n",
    "ax[1].imshow(img_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import base64\n",
    "\n",
    "list_images_base64 = []\n",
    "local_images = [\"images/image_1.png\", \"images/image_2.png\"]\n",
    "\n",
    "\n",
    "system_prompt=\"You have perfect vision and pay great attention to detail which makes you an expert at finding differences between images. Answer question in <question></question> tags, answer must be inside <answer></answer> tag. Before answer,  Think step by step in <thinking> tags and analyze every part of the image.\"\n",
    "prompt=\"List all difference between the two pictures ?\"\n",
    "messages={\"role\": \"user\", \"content\": [\n",
    "        {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Image 1:\"\n",
    "            },\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": \"image/jpeg\",\n",
    "                \"data\": image_to_base64(local_images[0]),\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Image 2:\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": \"image/jpeg\",\n",
    "                \"data\": image_to_base64(local_images[1]),\n",
    "            }\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": prompt}\n",
    "    ]}\n",
    "# Generate answer\n",
    "answer= generate_vision_answer(bedrock_rt, messages, model_id, claude_config, system_prompt)    \n",
    "print(colored(answer, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 4: Image Transcription with Claude 3 Sonnet on Amazon Bedrock \n",
    "\n",
    "In this use case, we will explore how to use Claude 3 Sonnet to transcribe text from an image. This can be particularly useful for extracting text from:\n",
    "\n",
    "1. Images\n",
    "2. Charts\n",
    "3. Diagram\n",
    "4. Technical Drawings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\"images/organigram.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = {\n",
    "        \"role\": 'user',\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": image_to_base64(\"images/organigram.jpeg\")}},\n",
    "            {\"type\": \"text\", \"text\": \"Turn this org chart into JSON indicating who reports to who, answer inside <answer></answer> tags.\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Generate answer\n",
    "answer= generate_vision_answer(bedrock_rt, messages, model_id, claude_config, system_prompt=\"\")\n",
    "print(colored(answer, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 5: Streaming Text with Claude 3 Sonnet on Amazon Bedrock\n",
    "\n",
    "In this use case, we'll explore how to harness the power of Claude 3 Sonnet to stream text. This functionality proves particularly beneficial for:\n",
    "\n",
    "- Real-time updates\n",
    "- Live conversations\n",
    "- Dynamic content generation\n",
    "- Continuous text processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaming with Bedrock 3\n",
    "\n",
    "\n",
    "def stream_answer(bedrock_rt:boto3.client, model_id:str, claude_config:dict, prompt:str):\n",
    "    stream_answer={\"role\": \"user\", \"content\": prompt}\n",
    "    \n",
    "    body={'messages': [stream_answer],**claude_config}\n",
    "    response = bedrock_rt.invoke_model_with_response_stream(modelId=model_id, body=json.dumps(body))\n",
    "    response_stream = response.get('body')\n",
    "    for event in response_stream or []:\n",
    "        chunk_data = event.get('chunk')\n",
    "        if chunk_data:\n",
    "            chunk_obj = json.loads(chunk_data.get('bytes').decode())\n",
    "            delta = chunk_obj.get('delta', {})\n",
    "            text_content = delta.get('text', \"\")\n",
    "            yield str(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"What is AWS ? Answer must be concise and to the point.\"\n",
    "\n",
    "for answer in stream_answer(bedrock_rt, model_id, claude_config, prompt):\n",
    "    print(answer,end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#3498db\">Optional: Put Words in Claude's Mouth</span>\n",
    "\n",
    "**Why prefill Claude's response?**\n",
    "\n",
    "Prefilling Claude's response offers several key benefits:\n",
    "- **Increased steerability**: By providing some initial text for Claude to continue from, you can steer Claude's response in a desired direction. This is particularly useful when you want Claude to focus on a specific topic, generate a particular type of content, or act a certain way.\n",
    "\n",
    "- **Control output format**: Prefilling allows you to specify the exact format you want Claude to use for its output. This is especially handy when working with structured data formats like JSON or XML. For more details on this, see our guide on controlling output format.\n",
    "\n",
    "- **Maintain character consistency**: In role-play scenarios, prefilling Claude's response can help Claude stay in character throughout a long conversation. By consistently reminding Claude of its role in the Assistant message, you can better ensure that Claude maintains the desired persona. Check out keep Claude stay in character for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answer(bedrock_rt:boto3.client, prompt:str, model_id:str, claude_config:dict,system_prompt:str)->str:\n",
    "    \n",
    "\n",
    "    message={'messages': [{\"role\": \"user\", \"content\": prompt},\n",
    "                          {\"role\": \"assistant\", \"content\": \"The answer is\"}]}\n",
    "    \n",
    "    body={**message,**claude_config, \"system\": system_prompt}\n",
    "    \n",
    "    response = bedrock_rt.invoke_model(modelId=model_id, body=json.dumps(body))\n",
    "    response = json.loads(response['body'].read().decode('utf-8'))\n",
    "    return response['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"You are a biology student, answer following questions\"\n",
    "prompt=\"What is latin for Ant? (A) Apoidea, (B) Rhopalocera, (C) Formicidae\"\n",
    "response=generate_answer(bedrock_rt, prompt, model_id, claude_config,system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
